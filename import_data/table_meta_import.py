import pandas as pd
import clickhouse_connect
from typing import List

# ä½ æä¾›çš„è‹±æ–‡è¡¨åé¡ºåºï¼ˆç”¨äºç­›é€‰å’Œæ’åºï¼‰
TARGET_TABLES = [
    "ads_sap_reform_data_ai",
    "ads_sap_reform_data_related_ai",
    # ...ï¼ˆæ­¤å¤„çœç•¥ï¼Œä¿ç•™ä½ å®Œæ•´çš„åˆ—è¡¨ï¼‰
    "ads_sap_repair_long_text_add"
]

# æ›¿æ¢ä¸ºä½ çš„å®Œæ•´ TARGET_TABLES åˆ—è¡¨ï¼ˆå»ºè®®ä»ä¸Šä¸€ä¸ªè„šæœ¬å¤åˆ¶è¿‡æ¥ï¼‰
# ä¸ºèŠ‚çœç¯‡å¹…ï¼Œè¿™é‡Œç”¨å ä½ç¬¦ï¼Œå®é™…ä½¿ç”¨æ—¶è¯·ç²˜è´´å®Œæ•´åˆ—è¡¨
# ï¼ˆä½ å¯ä»¥åœ¨è„šæœ¬é¡¶éƒ¨ç›´æ¥ç²˜è´´ä½ ä¹‹å‰æä¾›çš„å…¨éƒ¨è¡¨åï¼‰

def read_ordered_excel(excel_path: str, table_col: str = "è‹±æ–‡è¡¨å") -> pd.DataFrame:
    """è¯»å– Excel å¹¶æŒ‰ TARGET_TABLES é¡ºåºè¿”å› DataFrame"""
    df = pd.read_excel(excel_path)
    if table_col not in df.columns:
        raise ValueError(f"åˆ— '{table_col}' ä¸å­˜åœ¨ã€‚å¯ç”¨åˆ—: {list(df.columns)}")
    
    df[table_col] = df[table_col].astype(str).str.strip()
    table_to_order = {name: i for i, name in enumerate(TARGET_TABLES)}
    filtered = df[df[table_col].isin(table_to_order)].copy()
    filtered['sort_key'] = filtered[table_col].map(table_to_order)
    result = filtered.sort_values('sort_key').drop(columns=['sort_key']).reset_index(drop=True)
    return result


def main():
    # === é…ç½®åŒº ===
    EXCEL_FILE = "/mnt/sda/PythonProject/CYJ_Project/text2sql/my_rag_vllm/rag_12-15/import_data/rag_table_meta.xlsx"      # â† æ›¿æ¢ä¸ºä½ çš„ Excel è·¯å¾„

    # ClickHouse è¿æ¥é…ç½®
    CK_HOST = "127.0.0.1"
    CK_PORT = 8123
    CK_USER = "default"
    CK_PASSWORD = "12345678"
    CK_DATABASE = "sap"                     # â† æ›¿æ¢ä¸ºä½ çš„æ•°æ®åº“å

    # ç›®æ ‡è¡¨å
    TARGET_TABLE = "table_meta"

    # === æ­¥éª¤ 1ï¼šè¯»å– Excel æ•°æ® ===
    print("ğŸ“¥ æ­£åœ¨è¯»å– Excel æ–‡ä»¶...")
    df = pd.read_excel(EXCEL_FILE)


    if df.empty:
        print("âŒ æ²¡æœ‰åŒ¹é…åˆ°ä»»ä½•è¡¨æ•°æ®ï¼Œé€€å‡ºã€‚")
        return

    print(f"âœ… æˆåŠŸåŠ è½½ {len(df)} è¡Œæ•°æ®ã€‚")

    # === æ­¥éª¤ 2ï¼šè¿æ¥ ClickHouse ===
    print("ğŸ”Œ æ­£åœ¨è¿æ¥ ClickHouse...")
    client = clickhouse_connect.get_client(
        host=CK_HOST,
        port=CK_PORT,
        username=CK_USER,
        password=CK_PASSWORD,
        database=CK_DATABASE
    )

    # === æ­¥éª¤ 3ï¼šåˆ é™¤å·²å­˜åœ¨çš„è¡¨ï¼ˆå¦‚æœå­˜åœ¨ï¼‰===
    print(f"ğŸ—‘ï¸  æ£€æŸ¥å¹¶åˆ é™¤å·²å­˜åœ¨çš„è¡¨ `{TARGET_TABLE}`ï¼ˆå¦‚æœå­˜åœ¨ï¼‰...")
    client.command(f"DROP TABLE IF EXISTS {TARGET_TABLE}")

    # === æ­¥éª¤ 4ï¼šåˆ›å»ºæ–°è¡¨ ===
    # æ ¹æ® DataFrame åˆ—åŠ¨æ€ç”Ÿæˆè¡¨ç»“æ„ï¼ˆç®€å•æ˜ å°„ï¼‰
    # æ³¨æ„ï¼šè¿™é‡Œå‡è®¾æ‰€æœ‰åˆ—éƒ½æ˜¯ String ç±»å‹ï¼ˆé€‚åˆå…ƒæ•°æ®ï¼‰
    # å¦‚æœä½ æœ‰æ—¥æœŸã€æ•´æ•°ç­‰ï¼Œéœ€æ‰‹åŠ¨è°ƒæ•´ç±»å‹
    create_query = f"""
    CREATE TABLE IF NOT EXISTS {TARGET_TABLE} (
    id UInt32 COMMENT 'åºå·',
    table_name_en String COMMENT 'è‹±æ–‡è¡¨å',
    table_name_cn String COMMENT 'ä¸­æ–‡è¡¨å',
    raw_remark String COMMENT 'å¤‡æ³¨ï¼ˆåŸå§‹å¤‡æ³¨ï¼Œä¾›å‚è€ƒï¼‰',
    usage_scenarios String COMMENT 'ä½¿ç”¨åœºæ™¯ï¼ˆåŸå§‹ï¼‰',
    business_module_lvl1 String COMMENT 'ä¸€çº§ä¸šåŠ¡æ¨¡å—',
    business_module_lvl2 String COMMENT 'äºŒçº§ä¸šåŠ¡æ¨¡å—',
    create_sql String COMMENT 'å»ºè¡¨è¯­å¥',
    field_mapping String COMMENT 'å­—æ®µæ˜ å°„',
    biz_object String COMMENT 'ä¸šåŠ¡å¯¹è±¡',
    biz_granularity String COMMENT 'ä¸šåŠ¡ç²’åº¦',
    primary_key_fields String COMMENT 'ä¸»ä¸šåŠ¡é”®',
    time_field String COMMENT 'ä¸»æ—¶é—´å­—æ®µ',
    related_tables String COMMENT 'å…³è”è¡¨åï¼Œå¤šå¼ è¡¨ç”¨é€—å·åˆ†éš”'
) ENGINE = MergeTree()
ORDER BY id;
    """
    print("ğŸ†• æ­£åœ¨åˆ›å»ºæ–°è¡¨...")
    client.command(create_query)

    # === æ­¥éª¤ 5ï¼šæ’å…¥æ•°æ® ===
    print("ğŸ“¤ æ­£åœ¨æ’å…¥æ•°æ®åˆ° ClickHouse...")
    """
    å°† Excel è¯»å–çš„ DataFrame åˆ†æ‰¹æ’å…¥ ClickHouse è¡¨
    """
    batch_size=1000
    total = len(df)
    rows = []

    for i, row in df.iterrows():
        try:
            seq = int(row.get("åºå·")) if pd.notna(row.get("åºå·")) else None
        except (ValueError, TypeError):
            seq = None

        record = (
            seq,
            row.get("è‹±æ–‡è¡¨å"),
            row.get("ä¸­æ–‡è¡¨å"),
            row.get("å¤‡æ³¨ï¼ˆåŸå§‹å¤‡æ³¨ï¼Œä¾›å‚è€ƒï¼‰"),
            row.get("ä½¿ç”¨åœºæ™¯ï¼ˆåŸå§‹ï¼‰"),
            row.get("ä¸€çº§ä¸šåŠ¡æ¨¡å—"),
            row.get("äºŒçº§ä¸šåŠ¡æ¨¡å—"),
            row.get("å»ºè¡¨è¯­å¥"),
            row.get("å­—æ®µæ˜ å°„"),
            row.get("ä¸šåŠ¡å¯¹è±¡"),
            row.get("ä¸šåŠ¡ç²’åº¦"),
            row.get("ä¸»ä¸šåŠ¡é”®"),
            row.get("ä¸»æ—¶é—´å­—æ®µ"),
            row.get("å…³è”è¡¨å(å¤šå¼ è¡¨,åˆ†éš”)"),
        )
        rows.append(record)

        # è¾¾åˆ°æ‰¹é‡ä¸Šé™æˆ–æœ€åä¸€è¡Œï¼Œæ‰§è¡Œä¸€æ¬¡æ‰¹é‡æ’å…¥
        if len(rows) >= batch_size or i == total - 1:
            values_sql_parts = []
            for r in rows:
                formatted_values = []
                for v in r:
                    if v is None or (isinstance(v, float) and pd.isna(v)):
                        formatted_values.append("NULL")
                    else:
                        # æ¸…ç†å•å¼•å·ï¼Œé˜²æ­¢ SQL é”™è¯¯
                        clean_v = str(v).replace("'", "")
                        formatted_values.append(f"'{clean_v}'")
                values_sql_parts.append("(" + ", ".join(formatted_values) + ")")

            values_sql = ", ".join(values_sql_parts)
            insert_sql = f"""
            INSERT INTO {TARGET_TABLE} (
                id, table_name_en, table_name_cn, 
                raw_remark, usage_scenarios,
                business_module_lvl1, business_module_lvl2,
                create_sql, field_mapping, biz_object,
                biz_granularity, primary_key_fields, time_field,
                related_tables
            ) VALUES {values_sql}
            """

            client.command(insert_sql)
            rows.clear()

    print(f"âœ… æˆåŠŸæ’å…¥ {total} æ¡è®°å½•åˆ° {TARGET_TABLE}")


if __name__ == "__main__":
    main()